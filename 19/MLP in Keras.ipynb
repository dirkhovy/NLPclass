{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Short intro to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Keras is a great Python library and a wrapper for existing neural network packages. It runs with either the `theano` or `tensorflow` backend libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Keras implements two main approaches:\n",
    "    \n",
    "    * the Sequential model\n",
    "    * the functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The main type of model is the **Sequential** model, a linear stack of layers. You will only need the functional API for more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sequential means that it takes a list of layers. You can add one layer at a time to the model. Here is a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "model.add(Dense(input_dim=100, units=64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,114\n",
      "Trainable params: 7,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the first layer you need to specify its dimensions, the remaining layers will infer the size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternative, equivalent formulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=100, units=64, activation='relu'))\n",
    "# model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then you can compile and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A complicated LSTM model is easly created: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dropout\n",
    "\n",
    "num_labels=2\n",
    "vocabulary_size=10000\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=128, input_dim=vocabulary_size, input_length=100))\n",
    "model.add(LSTM(units=64, activation='tanh'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the functional API each layer is a function and can be applied to another layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten\n",
    "\n",
    "# input: a sequence  of 5 integers, each representing a word (index between 0 and vocab_size).\n",
    "main_input = Input(shape=(5,), dtype='int32', name='main_input')\n",
    "\n",
    "# now the embedding layer will encode the input sequence\n",
    "# into a sequence of dense 128-dimensional vectors.\n",
    "embeds = Embedding(output_dim=128, input_dim=vocabulary_size, input_length=5)(main_input)\n",
    "flatten = Flatten()(embeds) # we flatten it as Dense expects a 2D input\n",
    "dense = Dense(64, activation='tanh')(flatten)\n",
    "\n",
    "# finally the softmax (logistic) output layer\n",
    "main_loss = Dense(num_labels, activation='softmax', name='main_output')(dense)\n",
    "aux_loss = Dense(num_labels, activation='softmax', name='aux_loss')(embeds)\n",
    "\n",
    "\n",
    "# the model is specified by connecting input and output\n",
    "model = Model(inputs=[main_input], outputs=[main_loss, aux_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 5, 128)       1280000     main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 640)          0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 64)           41024       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 2)            130         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "aux_loss (Dense)                (None, 5, 2)         258         embedding_5[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,321,412\n",
      "Trainable params: 1,321,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With the functional API you can create a lot fun models quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Multilayer-Perceptron/Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 ['neg' 'pos']\n",
      "(1800, 2000)\n",
      "[0 0 0 1 1 0 1 1 0 0] 1800\n",
      "200 ['pos' 'neg']\n",
      "(200, 2000)\n",
      "[1 0 0 0 1 0 0 1 0 0] 200\n",
      "Convert class vector to binary 1-hot encoding matrix (for use with categorical_crossentropy)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "\n",
    "max_features = 2000\n",
    "\n",
    "# read in the training data\n",
    "train_data = pd.read_csv('../data/sa_train.csv')\n",
    "print(len(train_data), train_data['output'].unique())\n",
    "\n",
    "# create TFIDF representations\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=0.001, max_df=0.75, stop_words='english', max_features=max_features)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_data.input)\n",
    "print(X_train.shape)\n",
    "\n",
    "# transform labels into numbers\n",
    "labels2numbers = LabelEncoder()\n",
    "\n",
    "y_train_org = labels2numbers.fit_transform(train_data['output'])\n",
    "print(y_train_org[:10], len(y_train_org))\n",
    "\n",
    "\n",
    "\n",
    "# read in test data\n",
    "test_data = pd.read_csv('../../lectures/17/sa_test.csv')\n",
    "print(len(test_data), test_data['output'].unique())\n",
    "\n",
    "X_test = vectorizer.transform(test_data.input)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test_org = labels2numbers.transform(test_data['output'])\n",
    "print(y_test_org[:10], len(y_test_org))\n",
    "\n",
    "# get number of classes for transformation\n",
    "num_classes = max(y_train_org) + 1\n",
    "\n",
    "print('Convert class vector to binary 1-hot encoding matrix (for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train_org, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test_org, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (1800, 2)\n",
      "y_test shape: (200, 2)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]] [0 0 0 1 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "print(y_train[:10], y_train_org[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Train on 1620 samples, validate on 180 samples\n",
      "Epoch 1/3\n",
      "1620/1620 [==============================] - 6s 4ms/step - loss: 0.5368 - acc: 0.7253 - val_loss: 0.3795 - val_acc: 0.8389\n",
      "Epoch 2/3\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 0.1940 - acc: 0.9272 - val_loss: 0.3578 - val_acc: 0.8667\n",
      "Epoch 3/3\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 0.0718 - acc: 0.9741 - val_loss: 0.4919 - val_acc: 0.8500\n",
      "200/200 [==============================] - 0s 257us/step\n",
      "Test loss: 0.6236532393097878\n",
      "Test accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "epochs = 3\n",
    "\n",
    "print('Building model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(units=512, input_shape=(max_features,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 512)               1024512   \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,090,434\n",
      "Trainable params: 1,090,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.2866777e-04 9.9937135e-01]\n",
      " [9.9993646e-01 6.3520070e-05]\n",
      " [5.1778119e-02 9.4822186e-01]\n",
      " [9.9949014e-01 5.0985441e-04]\n",
      " [5.9198932e-04 9.9940801e-01]\n",
      " [9.9157399e-01 8.4260479e-03]\n",
      " [1.6980013e-01 8.3019990e-01]\n",
      " [9.7704905e-01 2.2950966e-02]\n",
      " [9.9946707e-01 5.3293799e-04]\n",
      " [5.1475006e-01 4.8524991e-01]]\n"
     ]
    }
   ],
   "source": [
    "# output class probability matrix\n",
    "print(model.predict(X_test[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output actual class predictions\n",
    "model.predict_classes(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81       111\n",
      "           1       0.76      0.81      0.78        89\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       200\n",
      "   macro avg       0.80      0.80      0.80       200\n",
      "weighted avg       0.80      0.80      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "print(classification_report(y_test_org, model.predict_classes(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* [http://keras.io/#getting-started-30-seconds-to-keras](http://keras.io/#getting-started-30-seconds-to-keras)\n",
    "* [http://keras.io/getting-started/sequential-model-guide/](http://keras.io/getting-started/sequential-model-guide/)\n",
    "* [https://arxiv.org/pdf/1510.00726.pdf](https://arxiv.org/pdf/1510.00726.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
